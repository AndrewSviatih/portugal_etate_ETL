version: '3.8'

services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - "2181:2181"

  kafka: 
    image: confluentinc/cp-kafka:7.5.0 
    container_name: kafka 
    depends_on: 
      - zookeeper 
    environment: 
      KAFKA_BROKER_ID: 1 
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181 
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092 
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT 
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1 
    ports: 
      - "9092:9092" 

  spark-master:
    image: bitnami/spark:3.4
    container_name: spark-master
    environment:
      SPARK_MODE: master
    ports:
      - "7077:7077"  # Spark master port
      - "8080:8080"  # Spark UI
    volumes:
      - spark-data:/bitnami/spark

  spark-worker:
    image: bitnami/spark:3.4
    container_name: spark-worker
    depends_on:
      - spark-master
    environment:
      SPARK_MODE: worker
      SPARK_MASTER_URL: spark://spark-master:7077
    volumes:
      - spark-data:/bitnami/spark

  airflow:
    build: ./airflow
    container_name: airflow
    depends_on:
      - postgres
      - kafka
      - spark-master
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres:5432/airflow
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
    ports:
      - "8001:8080"  # Airflow Web UI
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./plugins:/opt/airflow/plugins
    command: bash -c "airflow db init && airflow scheduler & airflow webserver"
    restart: always

  postgres:
    image: postgres:14
    container_name: postgres
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data

volumes:
  spark-data:
  postgres_data: